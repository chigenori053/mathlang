{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Advanced Analysis and Log Mining\n",
                "\n",
                "This notebook demonstrates advanced techniques for analyzing student learning data and detecting error patterns.\n",
                "\n",
                "## Topics Covered\n",
                "- Log data extraction and processing\n",
                "- Pattern detection in student errors\n",
                "- Statistical analysis of learning outcomes\n",
                "- Visualization of learning trajectories"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup\n",
                "import sys\n",
                "sys.path.insert(0, '../..')\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "import json\n",
                "\n",
                "from core.learning_logger import LearningLogger\n",
                "from core.exercise_spec import load_exercise_spec\n",
                "from core.symbolic_engine import SymbolicEngine\n",
                "from core.computation_engine import ComputationEngine\n",
                "from core.hint_engine import HintEngine\n",
                "\n",
                "sns.set_style(\"whitegrid\")\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Loading and Processing Log Data\n",
                "\n",
                "Learn how to load and process MathLang learning logs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Create sample log data\n",
                "logger = LearningLogger()\n",
                "\n",
                "# Simulate a learning session\n",
                "logger.record(phase=\"problem\", expression=\"x + x\", rendered=\"Problem: x + x\", status=\"ok\")\n",
                "logger.record(phase=\"step\", expression=\"2*x\", rendered=\"Step: 2*x\", status=\"ok\")\n",
                "logger.record(phase=\"end\", expression=\"done\", rendered=\"End: done\", status=\"ok\")\n",
                "\n",
                "# Convert to DataFrame for analysis\n",
                "df = pd.DataFrame(logger.records)\n",
                "print(\"Log Data Structure:\")\n",
                "print(df.head())\n",
                "print(f\"\\nColumns: {df.columns.tolist()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Error Pattern Detection\n",
                "\n",
                "Identify common mistake patterns in student work."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ErrorPatternAnalyzer:\n",
                "    \"\"\"Analyze error patterns in learning logs.\"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.patterns = {}\n",
                "        \n",
                "    def analyze_logs(self, logs):\n",
                "        \"\"\"Extract error patterns from logs.\"\"\"\n",
                "        errors = [log for log in logs if log['status'] == 'mistake']\n",
                "        \n",
                "        for error in errors:\n",
                "            meta = error.get('meta', {})\n",
                "            reason = meta.get('reason', 'unknown')\n",
                "            \n",
                "            if reason not in self.patterns:\n",
                "                self.patterns[reason] = []\n",
                "            \n",
                "            self.patterns[reason].append({\n",
                "                'expression': error.get('expression'),\n",
                "                'phase': error.get('phase'),\n",
                "                'timestamp': error.get('timestamp')\n",
                "            })\n",
                "        \n",
                "        return self.patterns\n",
                "    \n",
                "    def get_pattern_frequencies(self):\n",
                "        \"\"\"Get frequency of each error pattern.\"\"\"\n",
                "        return {k: len(v) for k, v in self.patterns.items()}\n",
                "    \n",
                "    def visualize_patterns(self):\n",
                "        \"\"\"Visualize error pattern distribution.\"\"\"\n",
                "        freqs = self.get_pattern_frequencies()\n",
                "        \n",
                "        plt.figure(figsize=(10, 6))\n",
                "        plt.bar(freqs.keys(), freqs.values())\n",
                "        plt.xlabel('Error Pattern')\n",
                "        plt.ylabel('Frequency')\n",
                "        plt.title('Error Pattern Distribution')\n",
                "        plt.xticks(rotation=45, ha='right')\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "\n",
                "# Example usage\n",
                "analyzer = ErrorPatternAnalyzer()\n",
                "# analyzer.analyze_logs(your_logs)\n",
                "# analyzer.visualize_patterns()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Hint Effectiveness Analysis\n",
                "\n",
                "Analyze which hints are most effective for different error types."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_hint_effectiveness(logs):\n",
                "    \"\"\"Analyze correlation between hints and subsequent success.\"\"\"\n",
                "    \n",
                "    # Find all hint events\n",
                "    hint_events = []\n",
                "    for i, log in enumerate(logs):\n",
                "        if log['status'] == 'mistake' and 'hint' in log.get('meta', {}):\n",
                "            # Check if next attempt was successful\n",
                "            next_success = False\n",
                "            if i + 1 < len(logs) and logs[i + 1]['status'] == 'ok':\n",
                "                next_success = True\n",
                "            \n",
                "            hint_events.append({\n",
                "                'hint_type': log['meta'].get('hint', {}).get('type'),\n",
                "                'next_success': next_success\n",
                "            })\n",
                "    \n",
                "    # Calculate effectiveness\n",
                "    df = pd.DataFrame(hint_events)\n",
                "    if not df.empty:\n",
                "        effectiveness = df.groupby('hint_type')['next_success'].mean()\n",
                "        return effectiveness\n",
                "    return pd.Series()\n",
                "\n",
                "# Example\n",
                "# effectiveness = analyze_hint_effectiveness(your_logs)\n",
                "# print(f\"Hint Effectiveness:\\n{effectiveness}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Learning Trajectory Visualization\n",
                "\n",
                "Visualize how students progress through problems."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_learning_trajectory(logs):\n",
                "    \"\"\"Plot success rate over time.\"\"\"\n",
                "    df = pd.DataFrame(logs)\n",
                "    \n",
                "    # Calculate rolling success rate\n",
                "    df['success'] = (df['status'] == 'ok').astype(int)\n",
                "    df['step_num'] = range(len(df))\n",
                "    \n",
                "    # Rolling average\n",
                "    window = 5\n",
                "    df['rolling_success'] = df['success'].rolling(window=window, min_periods=1).mean()\n",
                "    \n",
                "    # Plot\n",
                "    plt.figure(figsize=(12, 6))\n",
                "    plt.plot(df['step_num'], df['rolling_success'], marker='o', linewidth=2)\n",
                "    plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.3, label='50% threshold')\n",
                "    plt.xlabel('Step Number')\n",
                "    plt.ylabel(f'Success Rate (rolling {window}-step average)')\n",
                "    plt.title('Learning Trajectory')\n",
                "    plt.ylim(0, 1.1)\n",
                "    plt.legend()\n",
                "    plt.grid(True, alpha=0.3)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Example\n",
                "# plot_learning_trajectory(your_logs)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Multi-Student Comparison\n",
                "\n",
                "Compare performance across multiple students."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compare_students(student_logs_dict):\n",
                "    \"\"\"Compare metrics across multiple students.\"\"\"\n",
                "    \n",
                "    metrics = []\n",
                "    for student_id, logs in student_logs_dict.items():\n",
                "        df = pd.DataFrame(logs)\n",
                "        \n",
                "        total_steps = len(df[df['phase'].isin(['step', 'end'])])\n",
                "        successful_steps = len(df[(df['phase'].isin(['step', 'end'])) & (df['status'] == 'ok')])\n",
                "        \n",
                "        metrics.append({\n",
                "            'student_id': student_id,\n",
                "            'total_steps': total_steps,\n",
                "            'successful_steps': successful_steps,\n",
                "            'success_rate': successful_steps / total_steps if total_steps > 0 else 0,\n",
                "            'errors': len(df[df['status'] == 'mistake'])\n",
                "        })\n",
                "    \n",
                "    comparison_df = pd.DataFrame(metrics)\n",
                "    \n",
                "    # Visualize\n",
                "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "    \n",
                "    # Success rates\n",
                "    axes[0].bar(comparison_df['student_id'], comparison_df['success_rate'])\n",
                "    axes[0].set_xlabel('Student ID')\n",
                "    axes[0].set_ylabel('Success Rate')\n",
                "    axes[0].set_title('Student Success Rates')\n",
                "    axes[0].set_ylim(0, 1)\n",
                "    \n",
                "    # Error counts\n",
                "    axes[1].bar(comparison_df['student_id'], comparison_df['errors'], color='coral')\n",
                "    axes[1].set_xlabel('Student ID')\n",
                "    axes[1].set_ylabel('Number of Errors')\n",
                "    axes[1].set_title('Error Frequency by Student')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    return comparison_df\n",
                "\n",
                "# Example\n",
                "# student_data = {\n",
                "#     'student_1': logs1,\n",
                "#     'student_2': logs2,\n",
                "#     'student_3': logs3\n",
                "# }\n",
                "# comparison = compare_students(student_data)\n",
                "# print(comparison)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Exercise Difficulty Analysis\n",
                "\n",
                "Analyze which exercises are most challenging."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_exercise_difficulty(exercise_logs_dict):\n",
                "    \"\"\"Analyze difficulty based on completion rates and error rates.\"\"\"\n",
                "    \n",
                "    difficulty_metrics = []\n",
                "    \n",
                "    for exercise_id, logs in exercise_logs_dict.items():\n",
                "        df = pd.DataFrame(logs)\n",
                "        \n",
                "        attempts = len(df[df['phase'] == 'step'])\n",
                "        errors = len(df[df['status'] == 'mistake'])\n",
                "        \n",
                "        difficulty_metrics.append({\n",
                "            'exercise_id': exercise_id,\n",
                "            'avg_attempts': attempts,\n",
                "            'error_rate': errors / attempts if attempts > 0 else 0\n",
                "        })\n",
                "    \n",
                "    return pd.DataFrame(difficulty_metrics)\n",
                "\n",
                "# Example usage would go here"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "This notebook provided tools for:\n",
                "- Processing and analyzing learning logs\n",
                "- Detecting error patterns\n",
                "- Evaluating hint effectiveness\n",
                "- Visualizing learning trajectories\n",
                "- Comparing student performance\n",
                "- Assessing exercise difficulty\n",
                "\n",
                "Use these techniques to gain insights into student learning and improve educational interventions."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}